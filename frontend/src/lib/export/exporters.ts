/**
 * Export Formatters
 * Core logic for converting experiment data to different formats
 */

import type { Experiment } from '@/types/experiment'
import { escapeCSVField, formatNumber, formatDate } from './utils'

/**
 * Export experiment data as JSON
 * Returns a formatted JSON string with all experiment data
 */
export function exportToJSON(experiment: Experiment): string {
  return JSON.stringify(experiment, null, 2)
}

/**
 * Export experiment data as CSV
 * Creates a flattened CSV with one row per response
 */
export function exportToCSV(experiment: Experiment): string {
  const headers = [
    'Response ID',
    'Temperature',
    'Top P',
    'Max Tokens',
    'Content',
    'Overall Score',
    'Length Score',
    'Coherence Score',
    'Structure Score',
    'Readability Score',
    'Completeness Score',
    'Specificity Score',
    'Tokens Used',
    'Latency (ms)',
    'Created At',
  ]

  const rows = experiment.responses.map((response) => [
    escapeCSVField(response.id),
    escapeCSVField(response.temperature),
    escapeCSVField(response.topP),
    escapeCSVField(response.maxTokens),
    escapeCSVField(response.text),
    escapeCSVField(formatNumber(response.metricsOverall)),
    escapeCSVField(formatNumber(response.metricsLength)),
    escapeCSVField(formatNumber(response.metricsCoherence)),
    escapeCSVField(formatNumber(response.metricsStructure)),
    escapeCSVField(formatNumber(response.metricsReadability)),
    escapeCSVField(formatNumber(response.metricsCompleteness)),
    escapeCSVField(formatNumber(response.metricsSpecificity)),
    escapeCSVField(response.tokensUsed),
    escapeCSVField(response.latencyMs),
    escapeCSVField(formatDate(response.createdAt)),
  ])

  const csvContent = [
    headers.join(','),
    ...rows.map((row) => row.join(',')),
  ].join('\n')

  return csvContent
}

/**
 * Export experiment data as Markdown
 * Creates a human-readable report with formatted sections
 */
export function exportToMarkdown(experiment: Experiment): string {
  const lines: string[] = []

  // Header
  lines.push('# LLM Lab Experiment Report')
  lines.push('')
  lines.push(`**Experiment ID:** ${experiment.id}`)
  lines.push(`**Created:** ${formatDate(experiment.createdAt)}`)
  lines.push('')

  // Prompt
  lines.push('## Prompt')
  lines.push('')
  lines.push(experiment.prompt)
  lines.push('')

  // Responses
  lines.push('## Responses')
  lines.push('')

  experiment.responses.forEach((response, index) => {
    lines.push(`### Response ${index + 1}`)
    lines.push('')

    // Parameters
    lines.push('**Parameters:**')
    lines.push(`- Temperature: ${response.temperature}`)
    lines.push(`- Top P: ${response.topP}`)
    lines.push(`- Max Tokens: ${response.maxTokens}`)
    lines.push('')

    // Quality Metrics
    lines.push('**Quality Metrics:**')
    lines.push(`- Overall Score: ${formatNumber(response.metricsOverall)}/100`)
    lines.push(`- Length Score: ${formatNumber(response.metricsLength)}/100`)
    lines.push(`- Coherence Score: ${formatNumber(response.metricsCoherence)}/100`)
    lines.push(`- Structure Score: ${formatNumber(response.metricsStructure)}/100`)
    lines.push(`- Readability Score: ${formatNumber(response.metricsReadability)}/100`)
    lines.push(`- Completeness Score: ${formatNumber(response.metricsCompleteness)}/100`)
    lines.push(`- Specificity Score: ${formatNumber(response.metricsSpecificity)}/100`)
    lines.push('')

    // Performance
    lines.push('**Performance:**')
    lines.push(`- Tokens Used: ${response.tokensUsed}`)
    lines.push(`- Generation Time: ${response.latencyMs}ms`)
    lines.push('')

    // Content
    lines.push('**Content:**')
    lines.push('')
    lines.push('```')
    lines.push(response.text)
    lines.push('```')
    lines.push('')
    lines.push('---')
    lines.push('')
  })

  // Footer
  lines.push('---')
  lines.push('')
  lines.push('*Generated by LLM Lab*')
  lines.push(`*Export Date: ${formatDate(new Date())}*`)

  return lines.join('\n')
}
